{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC  \n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, auc, roc_curve, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import validation_curve\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mpl_toolkits import mplot3d\n",
    "import boto3\n",
    "from boto.s3.key import Key\n",
    "import timeit\n",
    "from io import StringIO\n",
    "\n",
    "bucket_name = 'masidorov.cs229.ner'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8163\n",
      "Before dedupe= 8163 After dedupe= 3914\n"
     ]
    }
   ],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "data_lines = []\n",
    "for obj in bucket.objects.all():\n",
    "    key = obj.key\n",
    "    body = obj.get()['Body'].read().splitlines()\n",
    "    data_lines = body\n",
    "print(len(data_lines))\n",
    "\n",
    "INDEX_ID = 0\n",
    "INDEX_TAGGED = 1\n",
    "INDEX_TEXT = 2\n",
    "INDEX_ANNOTATION = 3\n",
    "\n",
    "# Annotation constants\n",
    "ANNOTATION_LABEL = 0\n",
    "ANNOTATION_TEXT = 1\n",
    "ANNOTATION_POINTS = 2\n",
    "\n",
    "ANNOTATION_POINTS_START = 1\n",
    "ANNOTATION_POINTS_STOP = 2\n",
    "\n",
    "# structure we do support:\n",
    "# (tagged, text, annotations)\n",
    "# annotations = [annotation]\n",
    "# annotation := (label, text, start, stop)\n",
    "contents = []\n",
    "\n",
    "id = 0\n",
    "for line in data_lines:\n",
    "    dat = json.loads(line)\n",
    "    content = dat[\"content\"]\n",
    "    tuple_annotations = []\n",
    "    annotations = dat[\"annotation\"]\n",
    "    tagged = False\n",
    "    if (annotations is not None):\n",
    "        tagged = True\n",
    "        for annotation in annotations:\n",
    "            label = annotation[\"label\"][0]\n",
    "            points = annotation[\"points\"]\n",
    "            tuple_annotation = (label)\n",
    "            \n",
    "            tuple_points = []\n",
    "            for point in points:\n",
    "                text = point[\"text\"]\n",
    "                start = point[\"start\"]\n",
    "                stop = point[\"end\"]\n",
    "                tuple_points.append((text, start, stop))\n",
    "            tuple_annotations.append((label,text, tuple_points))\n",
    "    contents.append((id, tagged, content, tuple_annotations))\n",
    "    id = id + 1\n",
    "    \n",
    "    \n",
    "#DEDUPLICATION\n",
    "content2tag = {}\n",
    "for tuple in contents:\n",
    "    tagged = tuple[INDEX_TAGGED]\n",
    "    text = tuple[INDEX_TEXT]\n",
    "    if text not in content2tag.keys():\n",
    "        content2tag[text] = tagged\n",
    "    if (not content2tag[text]) and tagged:\n",
    "        content2tag[text] = tagged\n",
    "        \n",
    "visited = {}\n",
    "dedupe_context = []\n",
    "for tuple in contents:\n",
    "    tagged = tuple[INDEX_TAGGED]\n",
    "    text = tuple[INDEX_TEXT]\n",
    "    \n",
    "    if text in visited.keys():\n",
    "        continue\n",
    "    \n",
    "    if (content2tag[text] == tagged):\n",
    "        visited[text] = True\n",
    "        dedupe_context.append(tuple)\n",
    "        \n",
    "print(\"Before dedupe=\", len(contents), \"After dedupe=\", len(dedupe_context))\n",
    "contents = dedupe_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3914\n"
     ]
    }
   ],
   "source": [
    "# Now we create 2 lists for analysis per each record \n",
    "# word list: [w1,w2,...]\n",
    "# tagging: [tag1, tag2,...] we assume that we have 1 tag per word\n",
    "# Method we iterate via contents, for each line:\n",
    "# 1) Extract text and extract intervals\n",
    "# 2) scan in text words and for each word try to find start match in annotation list\n",
    "\n",
    "# CONSTANTS WE USE\n",
    "TUPLE_ID = 0\n",
    "TUPLE_TAGGED_ID = 1\n",
    "TUPLE_WORD_LIST = 2\n",
    "TUPLE_TAG_LIST = 3\n",
    "\n",
    "# Extraction of the tagged entities\n",
    "def find_tag(start, stop, annotations):\n",
    "    for annotation in annotations:\n",
    "        points = annotation[ANNOTATION_POINTS]\n",
    "        #print(\"Annot=\", points)\n",
    "        point = points[0]\n",
    "        astart = point[ANNOTATION_POINTS_START]\n",
    "        astop = point[ANNOTATION_POINTS_STOP]\n",
    "        \n",
    "        if (start == astart):\n",
    "            return annotation[ANNOTATION_LABEL]\n",
    "        \n",
    "    return \"\"\n",
    "    \n",
    "\n",
    "# This function is doing a data processing\n",
    "def process_tuple(content):\n",
    "    id = content[INDEX_ID]\n",
    "    tagged = content[INDEX_TAGGED]\n",
    "    text = content[INDEX_TEXT]\n",
    "    \n",
    "    words = []\n",
    "    tags = []\n",
    "    \n",
    "    annotations = content[INDEX_ANNOTATION]\n",
    "    start = 0\n",
    "    stop = 0\n",
    "    for i in range(len(text) + 1):\n",
    "        if (i == len(text)) or text[i] == ' ':\n",
    "            stop = i\n",
    "            wlen = stop - start\n",
    "            \n",
    "            if wlen > 0:\n",
    "                tag = find_tag(start, stop, annotations)\n",
    "                words.append(text[start:stop])\n",
    "                tags.append(tag)\n",
    "\n",
    "            start = stop + 1\n",
    "    \n",
    "    return (id, tagged, words, tags)\n",
    "\n",
    "\n",
    "# We investigate the structure of ptuple and ann\n",
    "# price like \"under $300\"\n",
    "# price like \"$300 after discount\"\n",
    "# \"item under discount\" item \"for $300\"\n",
    "def augment_tuple(ptuple):\n",
    "    \n",
    "    return ptuple\n",
    "\n",
    "pcontents = [process_tuple(content) for content in contents]\n",
    "\n",
    "\n",
    "\n",
    "print(len(pcontents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size= 6564  Dev set size= 346\n"
     ]
    }
   ],
   "source": [
    "# \"item under discount\" item \"for $300\"\n",
    "def augment_tuple(ptuple, id):\n",
    "    tagged = ptuple[INDEX_TAGGED]\n",
    "    price_found = ('Price' in ptuple[TUPLE_TAG_LIST])\n",
    "    if price_found or not tagged:\n",
    "        return [(id, tagged, ptuple[TUPLE_WORD_LIST], ptuple[TUPLE_TAG_LIST])]\n",
    "    \n",
    "    res = [(id, tagged, ptuple[TUPLE_WORD_LIST], ptuple[TUPLE_TAG_LIST])]\n",
    "    id = id + 1\n",
    "    for i in range(3):\n",
    "        id = id + 1\n",
    "        words = ptuple[TUPLE_WORD_LIST]\n",
    "        tags = ptuple[TUPLE_TAG_LIST]\n",
    "        words = words + ['under']\n",
    "        tags = tags + ['']\n",
    "        \n",
    "        price = np.random.randint(10, 1000)\n",
    "        words = words + ['$'+str(price)]\n",
    "        tags = tags + ['Price']\n",
    "        res = res + [(id, tagged, words, tags)]\n",
    "        \n",
    "    \n",
    "    return res\n",
    "\n",
    "\n",
    "# Create training and dev set\n",
    "ROW_TAGGED = len( [x for x in pcontents if x[INDEX_TAGGED] == True])\n",
    "tagged_set = [x for x in pcontents if x[INDEX_TAGGED] == True]\n",
    "train_set_index= np.random.choice(ROW_TAGGED, size=int(ROW_TAGGED*0.95), replace=False)\n",
    "\n",
    "dev_set_index = list(set(range(ROW_TAGGED)) - set(train_set_index))\n",
    "train_set = [tagged_set[i] for i in train_set_index]\n",
    "dev_set = [tagged_set[i] for i in dev_set_index]\n",
    "\n",
    "\n",
    "train_pcontents = []\n",
    "id = 1\n",
    "for pcontent in train_set:\n",
    "    tuples = augment_tuple(pcontent, id)\n",
    "    id = id + len(tuples)\n",
    "    train_pcontents = train_pcontents + tuples\n",
    "\n",
    "\n",
    "dev_pcontents = []\n",
    "for pcontent in dev_set:\n",
    "    tuples = augment_tuple(pcontent, id)\n",
    "    id = id + len(tuples)\n",
    "    dev_pcontents = dev_pcontents + tuples\n",
    "    \n",
    "\n",
    "\n",
    "#print(len(pcontents),len(ppcontents))\n",
    "train_set = train_pcontents\n",
    "dev_set = dev_pcontents\n",
    "\n",
    "print('Train set size=', len(train_set), ' Dev set size=', len(dev_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, True, ['apple', 'watch'], ['Brand', 'Category'])\n"
     ]
    }
   ],
   "source": [
    "# Definition of the features extraction\n",
    "\n",
    "class FeatureExtractor:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        \n",
    "    # sentense tuple is the result of process_tuple\n",
    "    # we extract features from tuple and return feature value in format\n",
    "    # (true/false, FeatureName, FeatureValue)\n",
    "    def extract(self, word_id, sentense_tupe, addition_mode):\n",
    "        pass\n",
    "    \n",
    "    # Return list of features supported by current features extractor\n",
    "    def features_list(self):\n",
    "        return [self.name]\n",
    "\n",
    "# Check if Hypen is inside\n",
    "class FE_HyphenInside(FeatureExtractor):\n",
    "    def __init__(self):\n",
    "        super(FE_HyphenInside, self).__init__('HyphenInside')\n",
    "        \n",
    "    def extract(self, word_id, sentense_tupe, addition_mode):\n",
    "        word = sentense_tupe[TUPLE_WORD_LIST][word_id]\n",
    "        return (True, self.name, '-' in word)\n",
    "\n",
    "\n",
    "# Check if Hypen is inside\n",
    "class FE_IsNumber(FeatureExtractor):\n",
    "    def __init__(self):\n",
    "        super(FE_IsNumber, self).__init__('IsNumber')\n",
    "        \n",
    "    def extract(self, word_id, sentense_tupe, addition_mode):\n",
    "        word = sentense_tupe[TUPLE_WORD_LIST][word_id]\n",
    "        return (True, self.name, word.isdigit())\n",
    "\n",
    "# Check started with dollar decimal/ended with dollar\n",
    "class FE_StartedDollar(FeatureExtractor):\n",
    "    def __init__(self):\n",
    "        super(FE_StartedDollar, self).__init__('StartedDollar')\n",
    "        \n",
    "    def extract(self, word_id, sentense_tupe, addition_mode):\n",
    "        word = sentense_tupe[TUPLE_WORD_LIST][word_id]\n",
    "        dollar =  len(word) > 0 and '$' == word[0] \n",
    "        return (True, self.name, dollar)\n",
    "\n",
    "\n",
    "# Check started digit\n",
    "class FE_StartedDigit(FeatureExtractor):\n",
    "    def __init__(self):\n",
    "        super(FE_StartedDigit, self).__init__('StartedDigit')\n",
    "        \n",
    "    def extract(self, word_id, sentense_tupe, addition_mode):\n",
    "        word = sentense_tupe[TUPLE_WORD_LIST][word_id]\n",
    "        digit =  len(word) > 0 and '9' >= word[0] and '0' <= word[0] \n",
    "        return (True, self.name, digit)\n",
    "\n",
    "# Check end digit\n",
    "class FE_EndDigit(FeatureExtractor):\n",
    "    def __init__(self):\n",
    "        super(FE_EndDigit, self).__init__('EndDigit')\n",
    "        \n",
    "    def extract(self, word_id, sentense_tupe, addition_mode):\n",
    "        word = sentense_tupe[TUPLE_WORD_LIST][word_id]\n",
    "        ll = len(word)\n",
    "        digit =  ll > 0 and '9' >= word[ll-1] and '0' <= word[ll-1] \n",
    "        return (True, self.name, digit)\n",
    "\n",
    "\n",
    "# True if no letters included\n",
    "class FE_DoesNotHaveLetters(FeatureExtractor):\n",
    "    def __init__(self):\n",
    "        super(FE_DoesNotHaveLetters, self).__init__('NoLetters')\n",
    "        \n",
    "    def extract(self, word_id, sentense_tupe, addition_mode):\n",
    "        word = sentense_tupe[TUPLE_WORD_LIST][word_id]\n",
    "        for c in word:\n",
    "            if c >= 'a' and c <= 'z':\n",
    "                return (True, self.name, False)\n",
    "            if c >= 'A' and c <= 'Z':\n",
    "                return (True, self.name, False)\n",
    "            \n",
    "        return (True, self.name, True)\n",
    "\n",
    "\n",
    "# Word position\n",
    "class FE_WordPos(FeatureExtractor):\n",
    "    def __init__(self):\n",
    "        super(FE_WordPos, self).__init__('WordPosition')\n",
    "        \n",
    "    def extract(self, word_id, sentense_tupe, addition_mode):\n",
    "        return (True, self.name, word_id)\n",
    "\n",
    "\n",
    "# and before\n",
    "class FE_And_Pos_M1(FeatureExtractor):\n",
    "    def __init__(self):\n",
    "        super(FE_And_Pos_M1, self).__init__('And_Pos_M1')\n",
    "        \n",
    "    def extract(self, word_id, sentense_tupe, addition_mode):\n",
    "        andBefore = False\n",
    "        if word_id > 0:\n",
    "            word = sentense_tupe[TUPLE_WORD_LIST][word_id - 1]\n",
    "            andBefore = ('and' == word)                        \n",
    "        return (True, self.name, andBefore)\n",
    "\n",
    "# and after\n",
    "class FE_And_Pos_P1(FeatureExtractor):\n",
    "    def __init__(self):\n",
    "        super(FE_And_Pos_P1, self).__init__('And_Pos_P1')\n",
    "        \n",
    "    def extract(self, word_id, sentense_tupe, addition_mode):\n",
    "        andAfter = False\n",
    "        if word_id + 1< len(sentense_tupe[TUPLE_WORD_LIST]):\n",
    "            word = sentense_tupe[TUPLE_WORD_LIST][word_id + 1]\n",
    "            andAfter = ('and' == word)                        \n",
    "        return (True, self.name, andAfter)\n",
    "\n",
    "\n",
    "# Represent the current word itself\n",
    "class FE_W0(FeatureExtractor):\n",
    "    def __init__(self):\n",
    "        super(FE_W0, self).__init__('W0_')\n",
    "        self.word2index = {}\n",
    "        self.current_index = int(0)\n",
    "\n",
    "    def extract(self, word_id, sentense_tupe, addition_mode):\n",
    "        word = sentense_tupe[TUPLE_WORD_LIST][word_id]\n",
    "        if word not in self.word2index.keys():\n",
    "            if not addition_mode:\n",
    "                return (False, self.name, 0)\n",
    "            self.word2index[word] = self.current_index\n",
    "            self.current_index = int(self.current_index + 1)\n",
    "        return (True, self.name+str(self.word2index[word]), 1)\n",
    "    \n",
    "    def features_list(self):\n",
    "        return [self.name + str(i) for i in range(self.current_index)]\n",
    "    \n",
    "\n",
    "\n",
    "# Class which contains feature extractors we would like to apply\n",
    "class FeatureExtractionContainer:\n",
    "    def __init__(self):\n",
    "        self.feature_extractors = [FE_HyphenInside(), FE_IsNumber(), \n",
    "                                   FE_W0(), FE_StartedDollar(), FE_DoesNotHaveLetters(),\n",
    "                                   FE_StartedDigit(), FE_EndDigit(), FE_WordPos(),\n",
    "                                   FE_And_Pos_M1(), FE_And_Pos_P1()]\n",
    "\n",
    "    # This is extraction from one specific tuple\n",
    "    def extract_from_tuple(self, word_id, sentense_tuple, addition_mode):\n",
    "        features = {}\n",
    "        for fe in self.feature_extractors:\n",
    "            fe_result = fe.extract(word_id, sentense_tuple, addition_mode)\n",
    "            if fe_result[0]:\n",
    "                features[fe_result[1]] = fe_result[2]\n",
    "        return features\n",
    "    \n",
    "    # result is a list of tuples which will include\n",
    "    # word_features_list := (tuple_id, IS_TAGGED, word, word_id, tag, features)\n",
    "    def process_sentense(self, sentense_tuple, addition_mode):\n",
    "        result = []\n",
    "        tuple_id = sentense_tuple[TUPLE_ID]\n",
    "        tagged = sentense_tuple[TUPLE_TAGGED_ID]\n",
    "        \n",
    "        \n",
    "        for word_id in range(len(sentense_tuple[TUPLE_WORD_LIST])):\n",
    "            features = self.extract_from_tuple(word_id, sentense_tuple, addition_mode)\n",
    "            tag = sentense_tuple[TUPLE_TAG_LIST][word_id]\n",
    "            result.append( (tuple_id, tagged, sentense_tuple[TUPLE_WORD_LIST][word_id], word_id, tag, features) )\n",
    "            \n",
    "        return result\n",
    "\n",
    "    # result is a list of tuples which will include\n",
    "    # word_features_list := (tuple_id, IS_TAGGED, word, word_id, tag, features)\n",
    "    def process_sentenses(self, sentense_tuples, addition_mode=True):\n",
    "        result = []\n",
    "        for sentense in sentense_tuples:\n",
    "            result = result + self.process_sentense(sentense, addition_mode)\n",
    "            \n",
    "        return result\n",
    "        \n",
    "    # This function takes list of tuples produced by\n",
    "    # process_sentense and put it in nice pandas.DataFrame\n",
    "    def features_pandalizer(self, word_features_list):\n",
    "        features_vector = {}\n",
    "        features_vector['TupleID'] = []\n",
    "        features_vector['Tagged'] = []\n",
    "        features_vector['Tag'] = []\n",
    "        features_vector['word'] = []\n",
    "        features_vector['WordID'] = []\n",
    "        \n",
    "        # Inject features\n",
    "        for fe in self.feature_extractors:\n",
    "            for fname in fe.features_list():\n",
    "                features_vector[fname] = []\n",
    "        \n",
    "        # Phase of creating long lists\n",
    "        for word_features in word_features_list:\n",
    "            features_vector['TupleID'].append(word_features[0])\n",
    "            features_vector['Tagged'].append(word_features[1])\n",
    "            features_vector['Tag'].append(word_features[4])\n",
    "            features_vector['word'].append(word_features[2])\n",
    "            features_vector['WordID'].append(word_features[3])\n",
    "            \n",
    "            # working with features\n",
    "            for fe in self.feature_extractors:\n",
    "                for fname in fe.features_list():\n",
    "                    if fname in word_features[5].keys():\n",
    "                        #print('FName=', fname, ' Value=', word_features[5][fname])\n",
    "                        features_vector[fname].append(int(word_features[5][fname]))\n",
    "                    else:\n",
    "                        features_vector[fname].append( 0)\n",
    "                        \n",
    "            #print(features_vector)\n",
    "                        \n",
    "                        \n",
    "            \n",
    "        \n",
    "        df = pd.DataFrame(features_vector)\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "#DEBUGGING\n",
    "print(pcontents[0])\n",
    "fec= FeatureExtractionContainer()\n",
    "#all_features= fec.process_sentenses(pcontents)\n",
    "#print(all_features)\n",
    "#df = fec.features_pandalizer(all_features)\n",
    "#print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elpased time= 43.66325727599906\n"
     ]
    }
   ],
   "source": [
    "# do split traint/dev set\n",
    "# count of rows which\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "fex = FE_W0()\n",
    "fec= FeatureExtractionContainer()\n",
    "\n",
    "#print(pcontents[101], fex.extract(0, pcontents[101], False))\n",
    "\n",
    "#tid = 102\n",
    "#print(pcontents[tid])\n",
    "\n",
    "#all_features= fec.process_sentenses(pcontents[101:102], False)\n",
    "\n",
    "#df = fec.features_pandalizer(all_features)\n",
    "#print(df.head())\n",
    "\n",
    "# Arrange trainig and test set\n",
    "\n",
    "\n",
    "\n",
    "fec= FeatureExtractionContainer()\n",
    "train_set_feature= fec.process_sentenses(train_set)\n",
    "dev_set_feature= fec.process_sentenses(dev_set, False)\n",
    "\n",
    "\n",
    "\n",
    "df_train = fec.features_pandalizer(train_set_feature)\n",
    "\n",
    "df_dev = fec.features_pandalizer(dev_set_feature)\n",
    "\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "print('Elpased time=', elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9771061908345546 0.8974245115452931\n",
      "[[22648   231]\n",
      " [  347  2021]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.99      0.99     22879\n",
      "          1       0.90      0.85      0.87      2368\n",
      "\n",
      "avg / total       0.98      0.98      0.98     25247\n",
      "\n",
      "Accuracy: 0.9519546876856656 0.887444041782136\n",
      "[[19871   528]\n",
      " [  685  4163]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.97      0.97     20399\n",
      "          1       0.89      0.86      0.87      4848\n",
      "\n",
      "avg / total       0.95      0.95      0.95     25247\n",
      "\n",
      "Accuracy: 0.9676001109042659 0.9103568320278503\n",
      "[[21291   309]\n",
      " [  509  3138]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.99      0.98     21600\n",
      "          1       0.91      0.86      0.88      3647\n",
      "\n",
      "avg / total       0.97      0.97      0.97     25247\n",
      "\n",
      "Accuracy: 0.9987721313423377 1.0\n",
      "[[20314     0]\n",
      " [   31  4902]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     20314\n",
      "          1       1.00      0.99      1.00      4933\n",
      "\n",
      "avg / total       1.00      1.00      1.00     25247\n",
      "\n",
      "Elpased time= 24862.245640152996\n",
      "Accuracy: 0.9311355311355312 Detemined brands= 110 144\n",
      "Accuracy: 0.9311355311355312 0.5555555555555556\n",
      "[[1191   30]\n",
      " [  64   80]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.98      0.96      1221\n",
      "          1       0.73      0.56      0.63       144\n",
      "\n",
      "avg / total       0.93      0.93      0.93      1365\n",
      "\n",
      "Accuracy: 0.8388278388278388 Detemined brands= 285 249\n",
      "Accuracy: 0.8388278388278388 0.6305220883534136\n",
      "[[988 128]\n",
      " [ 92 157]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.89      0.90      1116\n",
      "          1       0.55      0.63      0.59       249\n",
      "\n",
      "avg / total       0.85      0.84      0.84      1365\n",
      "\n",
      "Accuracy: 0.8952380952380953 Detemined brands= 127 176\n",
      "Accuracy: 0.8952380952380953 0.45454545454545453\n",
      "[[1142   47]\n",
      " [  96   80]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.96      0.94      1189\n",
      "          1       0.63      0.45      0.53       176\n",
      "\n",
      "avg / total       0.88      0.90      0.89      1365\n",
      "\n",
      "Accuracy: 0.9992673992673993 Detemined brands= 259 260\n",
      "Accuracy: 0.9992673992673993 0.9961538461538462\n",
      "[[1105    0]\n",
      " [   1  259]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      1105\n",
      "          1       1.00      1.00      1.00       260\n",
      "\n",
      "avg / total       1.00      1.00      1.00      1365\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '6B9E8906846F0EED',\n",
       "  'HostId': 'RES5OspEv7IT1VTBAv4Z4S2af3Z1YF0DlRymvJYqkabe9QnQOl6nIF62i9onol1qKH+6pmlIw1s=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'RES5OspEv7IT1VTBAv4Z4S2af3Z1YF0DlRymvJYqkabe9QnQOl6nIF62i9onol1qKH+6pmlIw1s=',\n",
       "   'x-amz-request-id': '6B9E8906846F0EED',\n",
       "   'date': 'Mon, 03 Dec 2018 13:55:19 GMT',\n",
       "   'etag': '\"ba8223d8277ace25d6545d12455e8662\"',\n",
       "   'content-length': '0',\n",
       "   'server': 'AmazonS3'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"ba8223d8277ace25d6545d12455e8662\"'}"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training set\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "all_labels = ['Brand', 'Category', 'ModelName', 'Price']\n",
    "cls_per_ner = {}\n",
    "\n",
    "df_train_result = df_train.loc[:, ['TupleID', 'word','Tag']].copy()\n",
    "df_train_result = df_train_result.reindex(columns=df_train_result.columns.tolist() + all_labels)\n",
    "\n",
    "for label in all_labels:\n",
    "    #df.head()\n",
    "    df_train_copy = df_train.loc[:].copy()\n",
    "    df_train_copy['Y'] = df_train_copy.apply(lambda row: (1 if row['Tag'] == label else 0), axis=1)\n",
    "\n",
    "    df_train_copy.drop(['word', 'WordID', 'Tagged', 'TupleID', 'Tag'], axis=1, inplace=True)\n",
    "    #df1.head()\n",
    "\n",
    "    X_train = df_train_copy.drop('Y', axis=1)\n",
    "    Y_train = df_train_copy['Y']\n",
    "\n",
    "    svc = SVC(kernel='rbf', gamma=0.7, probability=True)\n",
    "    clf = svc.fit(X_train, Y_train)\n",
    "    y_pred = clf.predict(X_train)\n",
    "    y_pred_porbability = clf.predict_proba(X_train)\n",
    "    df_train_result[label] = y_pred_porbability[:,1]\n",
    "    cls_per_ner[label] = clf\n",
    "    print(\"Accuracy:\",metrics.accuracy_score(Y_train, y_pred), metrics.precision_score(Y_train, y_pred))\n",
    "    print(confusion_matrix(Y_train, y_pred))\n",
    "\n",
    "    print(classification_report(Y_train, y_pred))\n",
    "\n",
    "\n",
    "#param_grid = {'C':[0.6, 0.8,1, 1.2, 2], 'gamma': [3, 2.5,2, 1.8, 1.6]}\n",
    "#model_search = GridSearchCV(SVC(probability=True), param_grid, verbose=2)\n",
    "\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "print('Elpased time=', elapsed)\n",
    "\n",
    "csv_buffer = StringIO()\n",
    "df_train_result.to_csv(csv_buffer)\n",
    "s3.Object(bucket_name, 'train_svm_result.csv').put(Body=csv_buffer.getvalue())\n",
    "\n",
    "\n",
    "#DEV set\n",
    "\n",
    "df_dev_result = df_dev.loc[:, ['TupleID', 'word','Tag']].copy()\n",
    "df_dev_result = df_dev_result.reindex(columns=df_dev_result.columns.tolist() + all_labels)\n",
    "\n",
    "for label in all_labels:\n",
    "    clf = cls_per_ner[label]\n",
    "\n",
    "    df_dev_copy = df_dev.copy()\n",
    "    df_dev_copy['Y'] = df_dev_copy.apply(lambda row: (1 if row['Tag'] == label else 0), axis=1)\n",
    "\n",
    "    df_dev_copy.drop(['word', 'WordID', 'Tagged', 'TupleID', 'Tag'], axis=1, inplace=True)\n",
    "    #df1.head()\n",
    "\n",
    "    X_dev = df_dev_copy.drop('Y', axis=1)\n",
    "    Y_dev = df_dev_copy['Y']\n",
    "\n",
    "    y_pred = clf.predict(X_dev)\n",
    "    y_pred_porbability = clf.predict_proba(X_dev)\n",
    "    df_dev_result[label] = y_pred_porbability[:,1]\n",
    "\n",
    "    print(\"Accuracy:\",metrics.accuracy_score(Y_dev, y_pred), \"Detemined brands=\", np.sum(y_pred), np.sum(Y_dev))\n",
    "    print(\"Accuracy:\",metrics.accuracy_score(Y_dev, y_pred), metrics.recall_score(Y_dev, y_pred))\n",
    "\n",
    "    print(confusion_matrix(Y_dev, y_pred, [0, 1]))\n",
    "\n",
    "    print(classification_report(Y_dev, y_pred))\n",
    "\n",
    "csv_buffer = StringIO()\n",
    "df_dev_result.to_csv(csv_buffer)\n",
    "s3.Object(bucket_name, 'dev_svm_result.csv').put(Body=csv_buffer.getvalue())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================\n",
      "Label= Brand\n",
      "==========================\n",
      "Accuracy: 0.9311355311355312 Detemined brands= 110 144\n",
      "Accuracy: 0.9311355311355312 0.5555555555555556\n",
      "[[1191   30]\n",
      " [  64   80]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.98      0.96      1221\n",
      "          1       0.73      0.56      0.63       144\n",
      "\n",
      "avg / total       0.93      0.93      0.93      1365\n",
      "\n",
      "==========================\n",
      "Label= Category\n",
      "==========================\n",
      "Accuracy: 0.8388278388278388 Detemined brands= 285 249\n",
      "Accuracy: 0.8388278388278388 0.6305220883534136\n",
      "[[988 128]\n",
      " [ 92 157]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.89      0.90      1116\n",
      "          1       0.55      0.63      0.59       249\n",
      "\n",
      "avg / total       0.85      0.84      0.84      1365\n",
      "\n",
      "==========================\n",
      "Label= ModelName\n",
      "==========================\n",
      "Accuracy: 0.8952380952380953 Detemined brands= 127 176\n",
      "Accuracy: 0.8952380952380953 0.45454545454545453\n",
      "[[1142   47]\n",
      " [  96   80]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.96      0.94      1189\n",
      "          1       0.63      0.45      0.53       176\n",
      "\n",
      "avg / total       0.88      0.90      0.89      1365\n",
      "\n",
      "==========================\n",
      "Label= Price\n",
      "==========================\n",
      "Accuracy: 0.9992673992673993 Detemined brands= 259 260\n",
      "Accuracy: 0.9992673992673993 0.9961538461538462\n",
      "[[1105    0]\n",
      " [   1  259]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      1105\n",
      "          1       1.00      1.00      1.00       260\n",
      "\n",
      "avg / total       1.00      1.00      1.00      1365\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#DEV set\n",
    "\n",
    "df_dev_result = df_dev.loc[:, ['TupleID', 'word','Tag']].copy()\n",
    "df_dev_result = df_dev_result.reindex(columns=df_dev_result.columns.tolist() + all_labels)\n",
    "\n",
    "for label in all_labels:\n",
    "    clf = cls_per_ner[label]\n",
    "\n",
    "    df_dev_copy = df_dev.copy()\n",
    "    df_dev_copy['Y'] = df_dev_copy.apply(lambda row: (1 if row['Tag'] == label else 0), axis=1)\n",
    "\n",
    "    df_dev_copy.drop(['word', 'WordID', 'Tagged', 'TupleID', 'Tag'], axis=1, inplace=True)\n",
    "    #df1.head()\n",
    "\n",
    "    X_dev = df_dev_copy.drop('Y', axis=1)\n",
    "    Y_dev = df_dev_copy['Y']\n",
    "\n",
    "    y_pred = clf.predict(X_dev)\n",
    "    y_pred_porbability = clf.predict_proba(X_dev)\n",
    "    df_dev_result[label] = y_pred_porbability[:,1]\n",
    "\n",
    "    print('==========================')\n",
    "    print('Label=', label)\n",
    "    print('==========================')\n",
    "    print(\"Accuracy:\",metrics.accuracy_score(Y_dev, y_pred), \"Detemined brands=\", np.sum(y_pred), np.sum(Y_dev))\n",
    "    print(\"Accuracy:\",metrics.accuracy_score(Y_dev, y_pred), metrics.recall_score(Y_dev, y_pred))\n",
    "\n",
    "    print(confusion_matrix(Y_dev, y_pred, [0, 1]))\n",
    "\n",
    "    print(classification_report(Y_dev, y_pred))\n",
    "\n",
    "#csv_buffer = StringIO()\n",
    "#df_dev_result.to_csv(csv_buffer)\n",
    "#s3.Object(bucket_name, 'dev_svm_result.csv').put(Body=csv_buffer.getvalue())\n",
    "    \n",
    "#false_positive_rate, true_positive_rate, thresholds= metrics.roc_curve(Y_dev, y_pred, pos_label=1)\n",
    "#roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "\n",
    "#plt.title('Receiver Operating Characteristic')\n",
    "#plt.plot(false_positive_rate, true_positive_rate, 'b', label='AUC = %0.2f'% roc_auc)\n",
    "#plt.plot([0,1],[0,1],'r--')\n",
    "#plt.xlim([-0.1,1.2])\n",
    "#plt.ylim([-0.1,1.2])\n",
    "#plt.ylabel('True Positive Rate')\n",
    "#plt.xlabel('False Positive Rate')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.007623\n",
       "1      0.007611\n",
       "2      0.007606\n",
       "3      0.007623\n",
       "4      0.007611\n",
       "5      0.007606\n",
       "6      0.007320\n",
       "7      0.007627\n",
       "8      0.007623\n",
       "9      0.007611\n",
       "10     0.007606\n",
       "11     0.007320\n",
       "12     0.007619\n",
       "13     0.007623\n",
       "14     0.007611\n",
       "15     0.007606\n",
       "16     0.007320\n",
       "17     0.007628\n",
       "18     0.007617\n",
       "19     0.007604\n",
       "20     0.007625\n",
       "21     0.007612\n",
       "22     0.007617\n",
       "23     0.007604\n",
       "24     0.007625\n",
       "25     0.007612\n",
       "26     0.007622\n",
       "27     0.007606\n",
       "28     0.007617\n",
       "29     0.007604\n",
       "         ...   \n",
       "270    0.007620\n",
       "271    0.007617\n",
       "272    0.996960\n",
       "273    0.007625\n",
       "274    0.007624\n",
       "275    0.007622\n",
       "276    0.007603\n",
       "277    0.007641\n",
       "278    0.007623\n",
       "279    0.007641\n",
       "280    0.007623\n",
       "281    0.004581\n",
       "282    0.007614\n",
       "283    0.007641\n",
       "284    0.007623\n",
       "285    0.004581\n",
       "286    0.007625\n",
       "287    0.007641\n",
       "288    0.007623\n",
       "289    0.004581\n",
       "290    0.007625\n",
       "291    0.996969\n",
       "292    0.007630\n",
       "293    0.996969\n",
       "294    0.007630\n",
       "295    0.004581\n",
       "296    0.007616\n",
       "297    0.996969\n",
       "298    0.007630\n",
       "299    0.004581\n",
       "Name: word, Length: 300, dtype: float64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_train_result[label] = y_pred_porbability[:,1]\n",
    "#len(y_pred_porbability[:,1])\n",
    "#df_train_copy = df_train[:300].copy()\n",
    "#len(df_train_copy['word'])\n",
    "#df_train_result[label] = y_pred_porbability[:,1]\n",
    "#df_train_copy['Price'] = y_pred_porbability[:,1]\n",
    "df_train_copy['word']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_result['Price'] = y_pred_porbability[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TupleID</th>\n",
       "      <th>word</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Category</th>\n",
       "      <th>ModelName</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6565</td>\n",
       "      <td>sony</td>\n",
       "      <td>Brand</td>\n",
       "      <td>0.100981</td>\n",
       "      <td>0.023523</td>\n",
       "      <td>0.031562</td>\n",
       "      <td>0.003912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6565</td>\n",
       "      <td>xb50bs</td>\n",
       "      <td>ModelName</td>\n",
       "      <td>0.015399</td>\n",
       "      <td>0.185921</td>\n",
       "      <td>0.051500</td>\n",
       "      <td>0.003376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6565</td>\n",
       "      <td>extra</td>\n",
       "      <td></td>\n",
       "      <td>0.005847</td>\n",
       "      <td>0.296129</td>\n",
       "      <td>0.079183</td>\n",
       "      <td>0.005387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6565</td>\n",
       "      <td>bass</td>\n",
       "      <td></td>\n",
       "      <td>0.004986</td>\n",
       "      <td>0.955561</td>\n",
       "      <td>0.010156</td>\n",
       "      <td>0.000840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6567</td>\n",
       "      <td>sony</td>\n",
       "      <td>Brand</td>\n",
       "      <td>0.100981</td>\n",
       "      <td>0.023523</td>\n",
       "      <td>0.031562</td>\n",
       "      <td>0.003912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6567</td>\n",
       "      <td>xb50bs</td>\n",
       "      <td>ModelName</td>\n",
       "      <td>0.015399</td>\n",
       "      <td>0.185921</td>\n",
       "      <td>0.051500</td>\n",
       "      <td>0.003376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6567</td>\n",
       "      <td>extra</td>\n",
       "      <td></td>\n",
       "      <td>0.005847</td>\n",
       "      <td>0.296129</td>\n",
       "      <td>0.079183</td>\n",
       "      <td>0.005387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6567</td>\n",
       "      <td>bass</td>\n",
       "      <td></td>\n",
       "      <td>0.004986</td>\n",
       "      <td>0.955561</td>\n",
       "      <td>0.010156</td>\n",
       "      <td>0.000840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6567</td>\n",
       "      <td>under</td>\n",
       "      <td></td>\n",
       "      <td>0.005847</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>0.005471</td>\n",
       "      <td>0.002627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6567</td>\n",
       "      <td>$858</td>\n",
       "      <td>Price</td>\n",
       "      <td>0.006237</td>\n",
       "      <td>0.005815</td>\n",
       "      <td>0.007337</td>\n",
       "      <td>0.977309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6568</td>\n",
       "      <td>sony</td>\n",
       "      <td>Brand</td>\n",
       "      <td>0.100981</td>\n",
       "      <td>0.023523</td>\n",
       "      <td>0.031562</td>\n",
       "      <td>0.003912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6568</td>\n",
       "      <td>xb50bs</td>\n",
       "      <td>ModelName</td>\n",
       "      <td>0.015399</td>\n",
       "      <td>0.185921</td>\n",
       "      <td>0.051500</td>\n",
       "      <td>0.003376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6568</td>\n",
       "      <td>extra</td>\n",
       "      <td></td>\n",
       "      <td>0.005847</td>\n",
       "      <td>0.296129</td>\n",
       "      <td>0.079183</td>\n",
       "      <td>0.005387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6568</td>\n",
       "      <td>bass</td>\n",
       "      <td></td>\n",
       "      <td>0.004986</td>\n",
       "      <td>0.955561</td>\n",
       "      <td>0.010156</td>\n",
       "      <td>0.000840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6568</td>\n",
       "      <td>under</td>\n",
       "      <td></td>\n",
       "      <td>0.005847</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>0.005471</td>\n",
       "      <td>0.002627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6568</td>\n",
       "      <td>$921</td>\n",
       "      <td>Price</td>\n",
       "      <td>0.006237</td>\n",
       "      <td>0.005815</td>\n",
       "      <td>0.007337</td>\n",
       "      <td>0.977309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6569</td>\n",
       "      <td>sony</td>\n",
       "      <td>Brand</td>\n",
       "      <td>0.100981</td>\n",
       "      <td>0.023523</td>\n",
       "      <td>0.031562</td>\n",
       "      <td>0.003912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6569</td>\n",
       "      <td>xb50bs</td>\n",
       "      <td>ModelName</td>\n",
       "      <td>0.015399</td>\n",
       "      <td>0.185921</td>\n",
       "      <td>0.051500</td>\n",
       "      <td>0.003376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6569</td>\n",
       "      <td>extra</td>\n",
       "      <td></td>\n",
       "      <td>0.005847</td>\n",
       "      <td>0.296129</td>\n",
       "      <td>0.079183</td>\n",
       "      <td>0.005387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6569</td>\n",
       "      <td>bass</td>\n",
       "      <td></td>\n",
       "      <td>0.004986</td>\n",
       "      <td>0.955561</td>\n",
       "      <td>0.010156</td>\n",
       "      <td>0.000840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>6569</td>\n",
       "      <td>under</td>\n",
       "      <td></td>\n",
       "      <td>0.005847</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>0.005471</td>\n",
       "      <td>0.002627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>6569</td>\n",
       "      <td>$292</td>\n",
       "      <td>Price</td>\n",
       "      <td>0.006237</td>\n",
       "      <td>0.005815</td>\n",
       "      <td>0.007337</td>\n",
       "      <td>0.977309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6569</td>\n",
       "      <td>hp</td>\n",
       "      <td>Brand</td>\n",
       "      <td>0.100981</td>\n",
       "      <td>0.023523</td>\n",
       "      <td>0.031562</td>\n",
       "      <td>0.003912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>6569</td>\n",
       "      <td>m402dn</td>\n",
       "      <td>ModelName</td>\n",
       "      <td>0.026963</td>\n",
       "      <td>0.645891</td>\n",
       "      <td>0.074428</td>\n",
       "      <td>0.000050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6571</td>\n",
       "      <td>hp</td>\n",
       "      <td>Brand</td>\n",
       "      <td>0.100981</td>\n",
       "      <td>0.023523</td>\n",
       "      <td>0.031562</td>\n",
       "      <td>0.003912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>6571</td>\n",
       "      <td>m402dn</td>\n",
       "      <td>ModelName</td>\n",
       "      <td>0.026963</td>\n",
       "      <td>0.645891</td>\n",
       "      <td>0.074428</td>\n",
       "      <td>0.000050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>6571</td>\n",
       "      <td>under</td>\n",
       "      <td></td>\n",
       "      <td>0.003563</td>\n",
       "      <td>0.004303</td>\n",
       "      <td>0.005476</td>\n",
       "      <td>0.002625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>6571</td>\n",
       "      <td>$953</td>\n",
       "      <td>Price</td>\n",
       "      <td>0.006014</td>\n",
       "      <td>0.005245</td>\n",
       "      <td>0.006280</td>\n",
       "      <td>0.985964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>6572</td>\n",
       "      <td>hp</td>\n",
       "      <td>Brand</td>\n",
       "      <td>0.100981</td>\n",
       "      <td>0.023523</td>\n",
       "      <td>0.031562</td>\n",
       "      <td>0.003912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>6572</td>\n",
       "      <td>m402dn</td>\n",
       "      <td>ModelName</td>\n",
       "      <td>0.026963</td>\n",
       "      <td>0.645891</td>\n",
       "      <td>0.074428</td>\n",
       "      <td>0.000050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>6902</td>\n",
       "      <td>$67</td>\n",
       "      <td>Price</td>\n",
       "      <td>0.006016</td>\n",
       "      <td>0.005041</td>\n",
       "      <td>0.006229</td>\n",
       "      <td>0.985947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>6903</td>\n",
       "      <td>headphones</td>\n",
       "      <td>Category</td>\n",
       "      <td>0.100959</td>\n",
       "      <td>0.023741</td>\n",
       "      <td>0.031491</td>\n",
       "      <td>0.003900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>6903</td>\n",
       "      <td>with</td>\n",
       "      <td></td>\n",
       "      <td>0.015399</td>\n",
       "      <td>0.185921</td>\n",
       "      <td>0.051500</td>\n",
       "      <td>0.003376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1338</th>\n",
       "      <td>6903</td>\n",
       "      <td>mic</td>\n",
       "      <td>Category</td>\n",
       "      <td>0.003841</td>\n",
       "      <td>0.862051</td>\n",
       "      <td>0.180565</td>\n",
       "      <td>0.000129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1339</th>\n",
       "      <td>6903</td>\n",
       "      <td>under</td>\n",
       "      <td></td>\n",
       "      <td>0.005612</td>\n",
       "      <td>0.004310</td>\n",
       "      <td>0.004157</td>\n",
       "      <td>0.002232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1340</th>\n",
       "      <td>6903</td>\n",
       "      <td>$72</td>\n",
       "      <td>Price</td>\n",
       "      <td>0.005997</td>\n",
       "      <td>0.004949</td>\n",
       "      <td>0.006080</td>\n",
       "      <td>0.986828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1341</th>\n",
       "      <td>6903</td>\n",
       "      <td>oil</td>\n",
       "      <td>ModelName</td>\n",
       "      <td>0.100981</td>\n",
       "      <td>0.023523</td>\n",
       "      <td>0.031562</td>\n",
       "      <td>0.003912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1342</th>\n",
       "      <td>6905</td>\n",
       "      <td>oil</td>\n",
       "      <td>ModelName</td>\n",
       "      <td>0.100981</td>\n",
       "      <td>0.023523</td>\n",
       "      <td>0.031562</td>\n",
       "      <td>0.003912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1343</th>\n",
       "      <td>6905</td>\n",
       "      <td>under</td>\n",
       "      <td></td>\n",
       "      <td>0.005838</td>\n",
       "      <td>0.004311</td>\n",
       "      <td>0.005491</td>\n",
       "      <td>0.002581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1344</th>\n",
       "      <td>6905</td>\n",
       "      <td>$851</td>\n",
       "      <td>Price</td>\n",
       "      <td>0.006143</td>\n",
       "      <td>0.005823</td>\n",
       "      <td>0.008139</td>\n",
       "      <td>0.975628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345</th>\n",
       "      <td>6906</td>\n",
       "      <td>oil</td>\n",
       "      <td>ModelName</td>\n",
       "      <td>0.100981</td>\n",
       "      <td>0.023523</td>\n",
       "      <td>0.031562</td>\n",
       "      <td>0.003912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346</th>\n",
       "      <td>6906</td>\n",
       "      <td>under</td>\n",
       "      <td></td>\n",
       "      <td>0.005838</td>\n",
       "      <td>0.004311</td>\n",
       "      <td>0.005491</td>\n",
       "      <td>0.002581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1347</th>\n",
       "      <td>6906</td>\n",
       "      <td>$574</td>\n",
       "      <td>Price</td>\n",
       "      <td>0.006143</td>\n",
       "      <td>0.005823</td>\n",
       "      <td>0.008139</td>\n",
       "      <td>0.975628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1348</th>\n",
       "      <td>6907</td>\n",
       "      <td>oil</td>\n",
       "      <td>ModelName</td>\n",
       "      <td>0.100981</td>\n",
       "      <td>0.023523</td>\n",
       "      <td>0.031562</td>\n",
       "      <td>0.003912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1349</th>\n",
       "      <td>6907</td>\n",
       "      <td>under</td>\n",
       "      <td></td>\n",
       "      <td>0.005838</td>\n",
       "      <td>0.004311</td>\n",
       "      <td>0.005491</td>\n",
       "      <td>0.002581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1350</th>\n",
       "      <td>6907</td>\n",
       "      <td>$892</td>\n",
       "      <td>Price</td>\n",
       "      <td>0.006143</td>\n",
       "      <td>0.005823</td>\n",
       "      <td>0.008139</td>\n",
       "      <td>0.975628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1351</th>\n",
       "      <td>6907</td>\n",
       "      <td>hf</td>\n",
       "      <td></td>\n",
       "      <td>0.100981</td>\n",
       "      <td>0.023523</td>\n",
       "      <td>0.031562</td>\n",
       "      <td>0.003912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1352</th>\n",
       "      <td>6907</td>\n",
       "      <td>g40</td>\n",
       "      <td>RAM</td>\n",
       "      <td>0.012948</td>\n",
       "      <td>0.073045</td>\n",
       "      <td>0.383224</td>\n",
       "      <td>0.002506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1353</th>\n",
       "      <td>6909</td>\n",
       "      <td>hf</td>\n",
       "      <td></td>\n",
       "      <td>0.100981</td>\n",
       "      <td>0.023523</td>\n",
       "      <td>0.031562</td>\n",
       "      <td>0.003912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1354</th>\n",
       "      <td>6909</td>\n",
       "      <td>g40</td>\n",
       "      <td>RAM</td>\n",
       "      <td>0.012948</td>\n",
       "      <td>0.073045</td>\n",
       "      <td>0.383224</td>\n",
       "      <td>0.002506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1355</th>\n",
       "      <td>6909</td>\n",
       "      <td>under</td>\n",
       "      <td></td>\n",
       "      <td>0.003563</td>\n",
       "      <td>0.004303</td>\n",
       "      <td>0.005476</td>\n",
       "      <td>0.002625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1356</th>\n",
       "      <td>6909</td>\n",
       "      <td>$177</td>\n",
       "      <td>Price</td>\n",
       "      <td>0.006014</td>\n",
       "      <td>0.005245</td>\n",
       "      <td>0.006280</td>\n",
       "      <td>0.985964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1357</th>\n",
       "      <td>6910</td>\n",
       "      <td>hf</td>\n",
       "      <td></td>\n",
       "      <td>0.100981</td>\n",
       "      <td>0.023523</td>\n",
       "      <td>0.031562</td>\n",
       "      <td>0.003912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1358</th>\n",
       "      <td>6910</td>\n",
       "      <td>g40</td>\n",
       "      <td>RAM</td>\n",
       "      <td>0.012948</td>\n",
       "      <td>0.073045</td>\n",
       "      <td>0.383224</td>\n",
       "      <td>0.002506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1359</th>\n",
       "      <td>6910</td>\n",
       "      <td>under</td>\n",
       "      <td></td>\n",
       "      <td>0.003563</td>\n",
       "      <td>0.004303</td>\n",
       "      <td>0.005476</td>\n",
       "      <td>0.002625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1360</th>\n",
       "      <td>6910</td>\n",
       "      <td>$449</td>\n",
       "      <td>Price</td>\n",
       "      <td>0.005836</td>\n",
       "      <td>0.004311</td>\n",
       "      <td>0.005478</td>\n",
       "      <td>0.991581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1361</th>\n",
       "      <td>6911</td>\n",
       "      <td>hf</td>\n",
       "      <td></td>\n",
       "      <td>0.100981</td>\n",
       "      <td>0.023523</td>\n",
       "      <td>0.031562</td>\n",
       "      <td>0.003912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1362</th>\n",
       "      <td>6911</td>\n",
       "      <td>g40</td>\n",
       "      <td>RAM</td>\n",
       "      <td>0.012948</td>\n",
       "      <td>0.073045</td>\n",
       "      <td>0.383224</td>\n",
       "      <td>0.002506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1363</th>\n",
       "      <td>6911</td>\n",
       "      <td>under</td>\n",
       "      <td></td>\n",
       "      <td>0.003563</td>\n",
       "      <td>0.004303</td>\n",
       "      <td>0.005476</td>\n",
       "      <td>0.002625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1364</th>\n",
       "      <td>6911</td>\n",
       "      <td>$96</td>\n",
       "      <td>Price</td>\n",
       "      <td>0.006014</td>\n",
       "      <td>0.005245</td>\n",
       "      <td>0.006280</td>\n",
       "      <td>0.985964</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1365 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      TupleID        word        Tag     Brand  Category  ModelName     Price\n",
       "0        6565        sony      Brand  0.100981  0.023523   0.031562  0.003912\n",
       "1        6565      xb50bs  ModelName  0.015399  0.185921   0.051500  0.003376\n",
       "2        6565       extra             0.005847  0.296129   0.079183  0.005387\n",
       "3        6565        bass             0.004986  0.955561   0.010156  0.000840\n",
       "4        6567        sony      Brand  0.100981  0.023523   0.031562  0.003912\n",
       "5        6567      xb50bs  ModelName  0.015399  0.185921   0.051500  0.003376\n",
       "6        6567       extra             0.005847  0.296129   0.079183  0.005387\n",
       "7        6567        bass             0.004986  0.955561   0.010156  0.000840\n",
       "8        6567       under             0.005847  0.004300   0.005471  0.002627\n",
       "9        6567        $858      Price  0.006237  0.005815   0.007337  0.977309\n",
       "10       6568        sony      Brand  0.100981  0.023523   0.031562  0.003912\n",
       "11       6568      xb50bs  ModelName  0.015399  0.185921   0.051500  0.003376\n",
       "12       6568       extra             0.005847  0.296129   0.079183  0.005387\n",
       "13       6568        bass             0.004986  0.955561   0.010156  0.000840\n",
       "14       6568       under             0.005847  0.004300   0.005471  0.002627\n",
       "15       6568        $921      Price  0.006237  0.005815   0.007337  0.977309\n",
       "16       6569        sony      Brand  0.100981  0.023523   0.031562  0.003912\n",
       "17       6569      xb50bs  ModelName  0.015399  0.185921   0.051500  0.003376\n",
       "18       6569       extra             0.005847  0.296129   0.079183  0.005387\n",
       "19       6569        bass             0.004986  0.955561   0.010156  0.000840\n",
       "20       6569       under             0.005847  0.004300   0.005471  0.002627\n",
       "21       6569        $292      Price  0.006237  0.005815   0.007337  0.977309\n",
       "22       6569          hp      Brand  0.100981  0.023523   0.031562  0.003912\n",
       "23       6569      m402dn  ModelName  0.026963  0.645891   0.074428  0.000050\n",
       "24       6571          hp      Brand  0.100981  0.023523   0.031562  0.003912\n",
       "25       6571      m402dn  ModelName  0.026963  0.645891   0.074428  0.000050\n",
       "26       6571       under             0.003563  0.004303   0.005476  0.002625\n",
       "27       6571        $953      Price  0.006014  0.005245   0.006280  0.985964\n",
       "28       6572          hp      Brand  0.100981  0.023523   0.031562  0.003912\n",
       "29       6572      m402dn  ModelName  0.026963  0.645891   0.074428  0.000050\n",
       "...       ...         ...        ...       ...       ...        ...       ...\n",
       "1335     6902         $67      Price  0.006016  0.005041   0.006229  0.985947\n",
       "1336     6903  headphones   Category  0.100959  0.023741   0.031491  0.003900\n",
       "1337     6903        with             0.015399  0.185921   0.051500  0.003376\n",
       "1338     6903         mic   Category  0.003841  0.862051   0.180565  0.000129\n",
       "1339     6903       under             0.005612  0.004310   0.004157  0.002232\n",
       "1340     6903         $72      Price  0.005997  0.004949   0.006080  0.986828\n",
       "1341     6903         oil  ModelName  0.100981  0.023523   0.031562  0.003912\n",
       "1342     6905         oil  ModelName  0.100981  0.023523   0.031562  0.003912\n",
       "1343     6905       under             0.005838  0.004311   0.005491  0.002581\n",
       "1344     6905        $851      Price  0.006143  0.005823   0.008139  0.975628\n",
       "1345     6906         oil  ModelName  0.100981  0.023523   0.031562  0.003912\n",
       "1346     6906       under             0.005838  0.004311   0.005491  0.002581\n",
       "1347     6906        $574      Price  0.006143  0.005823   0.008139  0.975628\n",
       "1348     6907         oil  ModelName  0.100981  0.023523   0.031562  0.003912\n",
       "1349     6907       under             0.005838  0.004311   0.005491  0.002581\n",
       "1350     6907        $892      Price  0.006143  0.005823   0.008139  0.975628\n",
       "1351     6907          hf             0.100981  0.023523   0.031562  0.003912\n",
       "1352     6907         g40        RAM  0.012948  0.073045   0.383224  0.002506\n",
       "1353     6909          hf             0.100981  0.023523   0.031562  0.003912\n",
       "1354     6909         g40        RAM  0.012948  0.073045   0.383224  0.002506\n",
       "1355     6909       under             0.003563  0.004303   0.005476  0.002625\n",
       "1356     6909        $177      Price  0.006014  0.005245   0.006280  0.985964\n",
       "1357     6910          hf             0.100981  0.023523   0.031562  0.003912\n",
       "1358     6910         g40        RAM  0.012948  0.073045   0.383224  0.002506\n",
       "1359     6910       under             0.003563  0.004303   0.005476  0.002625\n",
       "1360     6910        $449      Price  0.005836  0.004311   0.005478  0.991581\n",
       "1361     6911          hf             0.100981  0.023523   0.031562  0.003912\n",
       "1362     6911         g40        RAM  0.012948  0.073045   0.383224  0.002506\n",
       "1363     6911       under             0.003563  0.004303   0.005476  0.002625\n",
       "1364     6911         $96      Price  0.006014  0.005245   0.006280  0.985964\n",
       "\n",
       "[1365 rows x 7 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
