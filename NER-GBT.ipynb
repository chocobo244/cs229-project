{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation of Gradient boosting trees\n",
    "\n",
    "import numpy as np\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC  \n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, auc, roc_curve, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import validation_curve\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mpl_toolkits import mplot3d\n",
    "import boto3\n",
    "from boto.s3.key import Key\n",
    "import timeit\n",
    "from io import StringIO\n",
    "from sklearn.ensemble import GradientBoostingClassifier \n",
    "import seaborn as sns\n",
    "\n",
    "bucket_name = 'masidorov.cs229.ner'\n",
    "data_file_name = 'all-items-2sets.json'\n",
    "\n",
    "#Usage: https://rcarneva.github.io/understanding-gradient-boosting-part-1.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8163\n",
      "Before dedupe= 8163 After dedupe= 3914\n"
     ]
    }
   ],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "# See bucket API: https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3.html#S3.Bucket.Object\n",
    "\n",
    "data_lines = []\n",
    "obj = bucket.Object(data_file_name)\n",
    "body = obj.get()['Body'].read().splitlines()\n",
    "data_lines = body\n",
    "print(len(data_lines))\n",
    "\n",
    "INDEX_ID = 0\n",
    "INDEX_TAGGED = 1\n",
    "INDEX_TEXT = 2\n",
    "INDEX_ANNOTATION = 3\n",
    "\n",
    "# Annotation constants\n",
    "ANNOTATION_LABEL = 0\n",
    "ANNOTATION_TEXT = 1\n",
    "ANNOTATION_POINTS = 2\n",
    "\n",
    "ANNOTATION_POINTS_START = 1\n",
    "ANNOTATION_POINTS_STOP = 2\n",
    "\n",
    "# structure we do support:\n",
    "# (tagged, text, annotations)\n",
    "# annotations = [annotation]\n",
    "# annotation := (label, text, start, stop)\n",
    "contents = []\n",
    "\n",
    "id = 0\n",
    "for line in data_lines:\n",
    "    dat = json.loads(line)\n",
    "    content = dat[\"content\"]\n",
    "    tuple_annotations = []\n",
    "    annotations = dat[\"annotation\"]\n",
    "    tagged = False\n",
    "    if (annotations is not None):\n",
    "        tagged = True\n",
    "        for annotation in annotations:\n",
    "            label = annotation[\"label\"][0]\n",
    "            points = annotation[\"points\"]\n",
    "            tuple_annotation = (label)\n",
    "            \n",
    "            tuple_points = []\n",
    "            for point in points:\n",
    "                text = point[\"text\"]\n",
    "                start = point[\"start\"]\n",
    "                stop = point[\"end\"]\n",
    "                tuple_points.append((text, start, stop))\n",
    "            tuple_annotations.append((label,text, tuple_points))\n",
    "    contents.append((id, tagged, content, tuple_annotations))\n",
    "    id = id + 1\n",
    "    \n",
    "    \n",
    "#DEDUPLICATION\n",
    "content2tag = {}\n",
    "for tuple in contents:\n",
    "    tagged = tuple[INDEX_TAGGED]\n",
    "    text = tuple[INDEX_TEXT]\n",
    "    if text not in content2tag.keys():\n",
    "        content2tag[text] = tagged\n",
    "    if (not content2tag[text]) and tagged:\n",
    "        content2tag[text] = tagged\n",
    "        \n",
    "visited = {}\n",
    "dedupe_context = []\n",
    "for tuple in contents:\n",
    "    tagged = tuple[INDEX_TAGGED]\n",
    "    text = tuple[INDEX_TEXT]\n",
    "    \n",
    "    if text in visited.keys():\n",
    "        continue\n",
    "    \n",
    "    if (content2tag[text] == tagged):\n",
    "        visited[text] = True\n",
    "        dedupe_context.append(tuple)\n",
    "        \n",
    "print(\"Before dedupe=\", len(contents), \"After dedupe=\", len(dedupe_context))\n",
    "contents = dedupe_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3914\n"
     ]
    }
   ],
   "source": [
    "# Now we create 2 lists for analysis per each record \n",
    "# word list: [w1,w2,...]\n",
    "# tagging: [tag1, tag2,...] we assume that we have 1 tag per word\n",
    "# Method we iterate via contents, for each line:\n",
    "# 1) Extract text and extract intervals\n",
    "# 2) scan in text words and for each word try to find start match in annotation list\n",
    "\n",
    "# CONSTANTS WE USE\n",
    "TUPLE_ID = 0\n",
    "TUPLE_TAGGED_ID = 1\n",
    "TUPLE_WORD_LIST = 2\n",
    "TUPLE_TAG_LIST = 3\n",
    "\n",
    "# Extraction of the tagged entities\n",
    "def find_tag(start, stop, annotations):\n",
    "    for annotation in annotations:\n",
    "        points = annotation[ANNOTATION_POINTS]\n",
    "        #print(\"Annot=\", points)\n",
    "        point = points[0]\n",
    "        astart = point[ANNOTATION_POINTS_START]\n",
    "        astop = point[ANNOTATION_POINTS_STOP]\n",
    "        \n",
    "        if (start == astart):\n",
    "            return annotation[ANNOTATION_LABEL]\n",
    "        \n",
    "    return \"\"\n",
    "    \n",
    "\n",
    "# This function is doing a data processing\n",
    "def process_tuple(content):\n",
    "    id = content[INDEX_ID]\n",
    "    tagged = content[INDEX_TAGGED]\n",
    "    text = content[INDEX_TEXT]\n",
    "    \n",
    "    words = []\n",
    "    tags = []\n",
    "    \n",
    "    annotations = content[INDEX_ANNOTATION]\n",
    "    start = 0\n",
    "    stop = 0\n",
    "    for i in range(len(text) + 1):\n",
    "        if (i == len(text)) or text[i] == ' ':\n",
    "            stop = i\n",
    "            wlen = stop - start\n",
    "            \n",
    "            if wlen > 0:\n",
    "                tag = find_tag(start, stop, annotations)\n",
    "                words.append(text[start:stop])\n",
    "                tags.append(tag)\n",
    "\n",
    "            start = stop + 1\n",
    "    \n",
    "    return (id, tagged, words, tags)\n",
    "\n",
    "\n",
    "# We investigate the structure of ptuple and ann\n",
    "# price like \"under $300\"\n",
    "# price like \"$300 after discount\"\n",
    "# \"item under discount\" item \"for $300\"\n",
    "def augment_tuple(ptuple):\n",
    "    \n",
    "    return ptuple\n",
    "\n",
    "pcontents = [process_tuple(content) for content in contents]\n",
    "\n",
    "\n",
    "\n",
    "print(len(pcontents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size= 6561  Dev set size= 349\n"
     ]
    }
   ],
   "source": [
    "# \"item under discount\" item \"for $300\"\n",
    "def augment_tuple(ptuple, id):\n",
    "    tagged = ptuple[INDEX_TAGGED]\n",
    "    price_found = ('Price' in ptuple[TUPLE_TAG_LIST])\n",
    "    if price_found or not tagged:\n",
    "        return [(id, tagged, ptuple[TUPLE_WORD_LIST], ptuple[TUPLE_TAG_LIST])]\n",
    "    \n",
    "    res = [(id, tagged, ptuple[TUPLE_WORD_LIST], ptuple[TUPLE_TAG_LIST])]\n",
    "    id = id + 1\n",
    "    for i in range(3):\n",
    "        id = id + 1\n",
    "        words = ptuple[TUPLE_WORD_LIST]\n",
    "        tags = ptuple[TUPLE_TAG_LIST]\n",
    "        words = words + ['under']\n",
    "        tags = tags + ['']\n",
    "        \n",
    "        price = np.random.randint(10, 1000)\n",
    "        words = words + ['$'+str(price)]\n",
    "        tags = tags + ['Price']\n",
    "        res = res + [(id, tagged, words, tags)]\n",
    "        \n",
    "    \n",
    "    return res\n",
    "\n",
    "\n",
    "# Create training and dev set\n",
    "ROW_TAGGED = len( [x for x in pcontents if x[INDEX_TAGGED] == True])\n",
    "tagged_set = [x for x in pcontents if x[INDEX_TAGGED] == True]\n",
    "train_set_index= np.random.choice(ROW_TAGGED, size=int(ROW_TAGGED*0.95), replace=False)\n",
    "\n",
    "dev_set_index = list(set(range(ROW_TAGGED)) - set(train_set_index))\n",
    "train_set = [tagged_set[i] for i in train_set_index]\n",
    "dev_set = [tagged_set[i] for i in dev_set_index]\n",
    "\n",
    "\n",
    "train_pcontents = []\n",
    "id = 1\n",
    "for pcontent in train_set:\n",
    "    tuples = augment_tuple(pcontent, id)\n",
    "    id = id + len(tuples)\n",
    "    train_pcontents = train_pcontents + tuples\n",
    "\n",
    "\n",
    "dev_pcontents = []\n",
    "for pcontent in dev_set:\n",
    "    tuples = augment_tuple(pcontent, id)\n",
    "    id = id + len(tuples)\n",
    "    dev_pcontents = dev_pcontents + tuples\n",
    "    \n",
    "\n",
    "\n",
    "#print(len(pcontents),len(ppcontents))\n",
    "train_set = train_pcontents\n",
    "dev_set = dev_pcontents\n",
    "\n",
    "print('Train set size=', len(train_set), ' Dev set size=', len(dev_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, True, ['apple', 'watch'], ['Brand', 'Category'])\n"
     ]
    }
   ],
   "source": [
    "# Definition of the features extraction\n",
    "\n",
    "class FeatureExtractor:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        \n",
    "    # sentense tuple is the result of process_tuple\n",
    "    # we extract features from tuple and return feature value in format\n",
    "    # (true/false, FeatureName, FeatureValue)\n",
    "    def extract(self, word_id, sentense_tupe, addition_mode):\n",
    "        pass\n",
    "    \n",
    "    # Return list of features supported by current features extractor\n",
    "    def features_list(self):\n",
    "        return [self.name]\n",
    "\n",
    "# Check if Hypen is inside\n",
    "class FE_HyphenInside(FeatureExtractor):\n",
    "    def __init__(self):\n",
    "        super(FE_HyphenInside, self).__init__('HyphenInside')\n",
    "        \n",
    "    def extract(self, word_id, sentense_tupe, addition_mode):\n",
    "        word = sentense_tupe[TUPLE_WORD_LIST][word_id]\n",
    "        return (True, self.name, '-' in word)\n",
    "\n",
    "\n",
    "# Check if Hypen is inside\n",
    "class FE_IsNumber(FeatureExtractor):\n",
    "    def __init__(self):\n",
    "        super(FE_IsNumber, self).__init__('IsNumber')\n",
    "        \n",
    "    def extract(self, word_id, sentense_tupe, addition_mode):\n",
    "        word = sentense_tupe[TUPLE_WORD_LIST][word_id]\n",
    "        return (True, self.name, word.isdigit())\n",
    "\n",
    "# Check started with dollar decimal/ended with dollar\n",
    "class FE_StartedDollar(FeatureExtractor):\n",
    "    def __init__(self):\n",
    "        super(FE_StartedDollar, self).__init__('StartedDollar')\n",
    "        \n",
    "    def extract(self, word_id, sentense_tupe, addition_mode):\n",
    "        word = sentense_tupe[TUPLE_WORD_LIST][word_id]\n",
    "        dollar =  len(word) > 0 and '$' == word[0] \n",
    "        return (True, self.name, dollar)\n",
    "\n",
    "\n",
    "# Check started digit\n",
    "class FE_StartedDigit(FeatureExtractor):\n",
    "    def __init__(self):\n",
    "        super(FE_StartedDigit, self).__init__('StartedDigit')\n",
    "        \n",
    "    def extract(self, word_id, sentense_tupe, addition_mode):\n",
    "        word = sentense_tupe[TUPLE_WORD_LIST][word_id]\n",
    "        digit =  len(word) > 0 and '9' >= word[0] and '0' <= word[0] \n",
    "        return (True, self.name, digit)\n",
    "\n",
    "# Check end digit\n",
    "class FE_EndDigit(FeatureExtractor):\n",
    "    def __init__(self):\n",
    "        super(FE_EndDigit, self).__init__('EndDigit')\n",
    "        \n",
    "    def extract(self, word_id, sentense_tupe, addition_mode):\n",
    "        word = sentense_tupe[TUPLE_WORD_LIST][word_id]\n",
    "        ll = len(word)\n",
    "        digit =  ll > 0 and '9' >= word[ll-1] and '0' <= word[ll-1] \n",
    "        return (True, self.name, digit)\n",
    "\n",
    "\n",
    "# True if no letters included\n",
    "class FE_DoesNotHaveLetters(FeatureExtractor):\n",
    "    def __init__(self):\n",
    "        super(FE_DoesNotHaveLetters, self).__init__('NoLetters')\n",
    "        \n",
    "    def extract(self, word_id, sentense_tupe, addition_mode):\n",
    "        word = sentense_tupe[TUPLE_WORD_LIST][word_id]\n",
    "        for c in word:\n",
    "            if c >= 'a' and c <= 'z':\n",
    "                return (True, self.name, False)\n",
    "            if c >= 'A' and c <= 'Z':\n",
    "                return (True, self.name, False)\n",
    "            \n",
    "        return (True, self.name, True)\n",
    "\n",
    "\n",
    "# Word position\n",
    "class FE_WordPos(FeatureExtractor):\n",
    "    def __init__(self):\n",
    "        super(FE_WordPos, self).__init__('WordPosition')\n",
    "        \n",
    "    def extract(self, word_id, sentense_tupe, addition_mode):\n",
    "        return (True, self.name, word_id)\n",
    "\n",
    "\n",
    "# and before\n",
    "class FE_And_Pos_M1(FeatureExtractor):\n",
    "    def __init__(self):\n",
    "        super(FE_And_Pos_M1, self).__init__('And_Pos_M1')\n",
    "        \n",
    "    def extract(self, word_id, sentense_tupe, addition_mode):\n",
    "        andBefore = False\n",
    "        if word_id > 0:\n",
    "            word = sentense_tupe[TUPLE_WORD_LIST][word_id - 1]\n",
    "            andBefore = ('and' == word)                        \n",
    "        return (True, self.name, andBefore)\n",
    "\n",
    "# and after\n",
    "class FE_And_Pos_P1(FeatureExtractor):\n",
    "    def __init__(self):\n",
    "        super(FE_And_Pos_P1, self).__init__('And_Pos_P1')\n",
    "        \n",
    "    def extract(self, word_id, sentense_tupe, addition_mode):\n",
    "        andAfter = False\n",
    "        if word_id + 1< len(sentense_tupe[TUPLE_WORD_LIST]):\n",
    "            word = sentense_tupe[TUPLE_WORD_LIST][word_id + 1]\n",
    "            andAfter = ('and' == word)                        \n",
    "        return (True, self.name, andAfter)\n",
    "\n",
    "\n",
    "# Represent the current word itself\n",
    "class FE_W0(FeatureExtractor):\n",
    "    def __init__(self):\n",
    "        super(FE_W0, self).__init__('W0_')\n",
    "        self.word2index = {}\n",
    "        self.current_index = int(0)\n",
    "\n",
    "    def extract(self, word_id, sentense_tupe, addition_mode):\n",
    "        word = sentense_tupe[TUPLE_WORD_LIST][word_id]\n",
    "        if word not in self.word2index.keys():\n",
    "            if not addition_mode:\n",
    "                return (False, self.name, 0)\n",
    "            self.word2index[word] = self.current_index\n",
    "            self.current_index = int(self.current_index + 1)\n",
    "        return (True, self.name+str(self.word2index[word]), 1)\n",
    "    \n",
    "    def features_list(self):\n",
    "        return [self.name + str(i) for i in range(self.current_index)]\n",
    "    \n",
    "\n",
    "\n",
    "# Class which contains feature extractors we would like to apply\n",
    "class FeatureExtractionContainer:\n",
    "    def __init__(self):\n",
    "        self.feature_extractors = [FE_HyphenInside(), FE_IsNumber(), \n",
    "                                   FE_W0(), FE_StartedDollar(), FE_DoesNotHaveLetters(),\n",
    "                                   FE_StartedDigit(), FE_EndDigit(), FE_WordPos(),\n",
    "                                   FE_And_Pos_M1(), FE_And_Pos_P1()]\n",
    "\n",
    "    # This is extraction from one specific tuple\n",
    "    def extract_from_tuple(self, word_id, sentense_tuple, addition_mode):\n",
    "        features = {}\n",
    "        for fe in self.feature_extractors:\n",
    "            fe_result = fe.extract(word_id, sentense_tuple, addition_mode)\n",
    "            if fe_result[0]:\n",
    "                features[fe_result[1]] = fe_result[2]\n",
    "        return features\n",
    "    \n",
    "    # result is a list of tuples which will include\n",
    "    # word_features_list := (tuple_id, IS_TAGGED, word, word_id, tag, features)\n",
    "    def process_sentense(self, sentense_tuple, addition_mode):\n",
    "        result = []\n",
    "        tuple_id = sentense_tuple[TUPLE_ID]\n",
    "        tagged = sentense_tuple[TUPLE_TAGGED_ID]\n",
    "        \n",
    "        \n",
    "        for word_id in range(len(sentense_tuple[TUPLE_WORD_LIST])):\n",
    "            features = self.extract_from_tuple(word_id, sentense_tuple, addition_mode)\n",
    "            tag = sentense_tuple[TUPLE_TAG_LIST][word_id]\n",
    "            result.append( (tuple_id, tagged, sentense_tuple[TUPLE_WORD_LIST][word_id], word_id, tag, features) )\n",
    "            \n",
    "        return result\n",
    "\n",
    "    # result is a list of tuples which will include\n",
    "    # word_features_list := (tuple_id, IS_TAGGED, word, word_id, tag, features)\n",
    "    def process_sentenses(self, sentense_tuples, addition_mode=True):\n",
    "        result = []\n",
    "        for sentense in sentense_tuples:\n",
    "            result = result + self.process_sentense(sentense, addition_mode)\n",
    "            \n",
    "        return result\n",
    "        \n",
    "    # This function takes list of tuples produced by\n",
    "    # process_sentense and put it in nice pandas.DataFrame\n",
    "    def features_pandalizer(self, word_features_list):\n",
    "        features_vector = {}\n",
    "        features_vector['TupleID'] = []\n",
    "        features_vector['Tagged'] = []\n",
    "        features_vector['Tag'] = []\n",
    "        features_vector['word'] = []\n",
    "        features_vector['WordID'] = []\n",
    "        \n",
    "        # Inject features\n",
    "        for fe in self.feature_extractors:\n",
    "            for fname in fe.features_list():\n",
    "                features_vector[fname] = []\n",
    "        \n",
    "        # Phase of creating long lists\n",
    "        for word_features in word_features_list:\n",
    "            features_vector['TupleID'].append(word_features[0])\n",
    "            features_vector['Tagged'].append(word_features[1])\n",
    "            features_vector['Tag'].append(word_features[4])\n",
    "            features_vector['word'].append(word_features[2])\n",
    "            features_vector['WordID'].append(word_features[3])\n",
    "            \n",
    "            # working with features\n",
    "            for fe in self.feature_extractors:\n",
    "                for fname in fe.features_list():\n",
    "                    if fname in word_features[5].keys():\n",
    "                        #print('FName=', fname, ' Value=', word_features[5][fname])\n",
    "                        features_vector[fname].append(int(word_features[5][fname]))\n",
    "                    else:\n",
    "                        features_vector[fname].append( 0)\n",
    "                        \n",
    "            #print(features_vector)\n",
    "                        \n",
    "                        \n",
    "            \n",
    "        \n",
    "        df = pd.DataFrame(features_vector)\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "#DEBUGGING\n",
    "print(pcontents[0])\n",
    "fec= FeatureExtractionContainer()\n",
    "#all_features= fec.process_sentenses(pcontents)\n",
    "#print(all_features)\n",
    "#df = fec.features_pandalizer(all_features)\n",
    "#print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# do split traint/dev set\n",
    "# count of rows which\n",
    "\n",
    "fex = FE_W0()\n",
    "fec= FeatureExtractionContainer()\n",
    "\n",
    "#print(pcontents[101], fex.extract(0, pcontents[101], False))\n",
    "\n",
    "#tid = 102\n",
    "#print(pcontents[tid])\n",
    "\n",
    "#all_features= fec.process_sentenses(pcontents[101:102], False)\n",
    "\n",
    "#df = fec.features_pandalizer(all_features)\n",
    "#print(df.head())\n",
    "\n",
    "# Arrange trainig and test set\n",
    "\n",
    "\n",
    "\n",
    "fec= FeatureExtractionContainer()\n",
    "train_set_feature= fec.process_sentenses(train_set)\n",
    "dev_set_feature= fec.process_sentenses(dev_set, False)\n",
    "\n",
    "\n",
    "\n",
    "df_train = fec.features_pandalizer(train_set_feature)\n",
    "\n",
    "df_dev = fec.features_pandalizer(dev_set_feature)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start label =  Brand\n",
      "Accuracy: 0.9730615791760477 0.8962616822429906\n",
      "[[22717   222]\n",
      " [  460  1918]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.99      0.99     22939\n",
      "          1       0.90      0.81      0.85      2378\n",
      "\n",
      "avg / total       0.97      0.97      0.97     25317\n",
      "\n",
      "Start label =  Category\n",
      "Accuracy: 0.946676146462851 0.8826742407690628\n",
      "[[19927   537]\n",
      " [  813  4040]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.97      0.97     20464\n",
      "          1       0.88      0.83      0.86      4853\n",
      "\n",
      "avg / total       0.95      0.95      0.95     25317\n",
      "\n",
      "Start label =  ModelName\n",
      "Accuracy: 0.9645692617608721 0.8928571428571429\n",
      "[[21345   369]\n",
      " [  528  3075]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.98      0.98     21714\n",
      "          1       0.89      0.85      0.87      3603\n",
      "\n",
      "avg / total       0.96      0.96      0.96     25317\n",
      "\n",
      "Start label =  Price\n",
      "Accuracy: 0.9989730220800253 0.9983762938908057\n",
      "[[20372     8]\n",
      " [   18  4919]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     20380\n",
      "          1       1.00      1.00      1.00      4937\n",
      "\n",
      "avg / total       1.00      1.00      1.00     25317\n",
      "\n",
      "Elpased time= 1458.8933555879921\n",
      "==========================\n",
      "Label= Brand\n",
      "==========================\n",
      "Accuracy: 0.9343629343629344 Detemined brands= 97 134\n",
      "Accuracy: 0.9343629343629344 0.5447761194029851\n",
      "==========================\n",
      "Label= Category\n",
      "==========================\n",
      "Accuracy: 0.8872586872586873 Detemined brands= 182 244\n",
      "Accuracy: 0.8872586872586873 0.5737704918032787\n",
      "==========================\n",
      "Label= ModelName\n",
      "==========================\n",
      "Accuracy: 0.8664092664092664 Detemined brands= 105 220\n",
      "Accuracy: 0.8664092664092664 0.34545454545454546\n",
      "==========================\n",
      "Label= Price\n",
      "==========================\n",
      "Accuracy: 0.9969111969111969 Detemined brands= 252 256\n",
      "Accuracy: 0.9969111969111969 0.984375\n",
      "Elpased time= 1460.624913666994\n"
     ]
    }
   ],
   "source": [
    "start_time = timeit.default_timer()\n",
    "\n",
    "all_labels = ['Brand', 'Category', 'ModelName', 'Price']\n",
    "cls_per_ner = {}\n",
    "\n",
    "df_train_result = df_train.loc[:, ['TupleID', 'word','Tag']].copy()\n",
    "df_train_result = df_train_result.reindex(columns=df_train_result.columns.tolist() + all_labels)\n",
    "\n",
    "#GBM parameters\n",
    "\n",
    "\n",
    "stage_preds = {}\n",
    "final_preds = {}\n",
    "\n",
    "depth = 3\n",
    "lr = 0.5\n",
    "estimators = [300,400,500,600,700,800]\n",
    "est = 500\n",
    "\n",
    "#all_labels = [ 'Category']\n",
    "for label in all_labels:\n",
    "    #df.head()\n",
    "    print('Start label = ', label)\n",
    "    common_args2 = {'max_depth': depth, 'n_estimators': est, 'subsample': 0.9, 'random_state': 2}\n",
    "    model  = GradientBoostingClassifier(learning_rate=lr, **common_args2)\n",
    "\n",
    "    df_train_copy = df_train.loc[:].copy()\n",
    "    df_train_copy['Y'] = df_train_copy.apply(lambda row: (1 if row['Tag'] == label else 0), axis=1)\n",
    "\n",
    "    df_train_copy.drop(['word', 'WordID', 'Tagged', 'TupleID', 'Tag'], axis=1, inplace=True)\n",
    "    #df1.head()\n",
    "\n",
    "    X_train = df_train_copy.drop('Y', axis=1)\n",
    "    Y_train = df_train_copy['Y']\n",
    "\n",
    "    #svc = SVC(kernel='rbf', gamma=0.7, probability=True)\n",
    "    clf = model.fit(X_train, Y_train)\n",
    "    cls_per_ner[label] = clf\n",
    "          \n",
    "    y_pred = clf.predict(X_train)\n",
    "    y_pred_porbability = clf.predict_proba(X_train)\n",
    "    df_train_result[label] = y_pred_porbability[:,1]\n",
    "    cls_per_ner[label] = clf\n",
    "\n",
    "    print(\"Accuracy:\",metrics.accuracy_score(Y_train, y_pred), metrics.precision_score(Y_train, y_pred))\n",
    "    print(confusion_matrix(Y_train, y_pred))\n",
    "\n",
    "    print(classification_report(Y_train, y_pred))\n",
    "\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "print('Elpased time=', elapsed)\n",
    "\n",
    "csv_buffer = StringIO()\n",
    "df_train_result.to_csv(csv_buffer)\n",
    "s3.Object(bucket_name, 'train_gbt_result.csv').put(Body=csv_buffer.getvalue())\n",
    "\n",
    "\n",
    "#DEV set\n",
    "\n",
    "df_dev_result = df_dev.loc[:, ['TupleID', 'word','Tag']].copy()\n",
    "df_dev_result = df_dev_result.reindex(columns=df_dev_result.columns.tolist() + all_labels)\n",
    "          \n",
    "for label in all_labels:\n",
    "              # Training error\n",
    "    df_dev_copy = df_dev.copy()\n",
    "    df_dev_copy['Y'] = df_dev_copy.apply(lambda row: (1 if row['Tag'] == label else 0), axis=1)\n",
    "    df_dev_copy.drop(['word', 'WordID', 'Tagged', 'TupleID', 'Tag'], axis=1, inplace=True)\n",
    "\n",
    "    X_dev = df_dev_copy.drop('Y', axis=1)\n",
    "    Y_dev = df_dev_copy['Y']\n",
    "\n",
    "    clf = cls_per_ner[label]\n",
    "    y_pred = clf.predict(X_dev)\n",
    "    y_pred_porbability = clf.predict_proba(X_dev)\n",
    "    df_dev_result[label] = y_pred_porbability[:,1]          \n",
    "\n",
    "    print('==========================')\n",
    "    print('Label=', label)\n",
    "    print('==========================')\n",
    "    print(\"Accuracy:\",metrics.accuracy_score(Y_dev, y_pred), \"Detemined brands=\", np.sum(y_pred), np.sum(Y_dev))\n",
    "    print(\"Accuracy:\",metrics.accuracy_score(Y_dev, y_pred), metrics.recall_score(Y_dev, y_pred))\n",
    "\n",
    "csv_buffer = StringIO()\n",
    "df_dev_result.to_csv(csv_buffer)\n",
    "s3.Object(bucket_name, 'dev_gbm_result.csv').put(Body=csv_buffer.getvalue())\n",
    "          \n",
    "elapsed = timeit.default_timer() - start_time\n",
    "print('Elpased time=', elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TupleID</th>\n",
       "      <th>word</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6571</td>\n",
       "      <td>apple</td>\n",
       "      <td>Brand</td>\n",
       "      <td>0.084158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6571</td>\n",
       "      <td>watch</td>\n",
       "      <td>Category</td>\n",
       "      <td>0.803335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6571</td>\n",
       "      <td>series</td>\n",
       "      <td>ModelName</td>\n",
       "      <td>0.105771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6571</td>\n",
       "      <td>3</td>\n",
       "      <td>ModelName</td>\n",
       "      <td>0.004829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6573</td>\n",
       "      <td>apple</td>\n",
       "      <td>Brand</td>\n",
       "      <td>0.084158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6573</td>\n",
       "      <td>watch</td>\n",
       "      <td>Category</td>\n",
       "      <td>0.803335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6573</td>\n",
       "      <td>series</td>\n",
       "      <td>ModelName</td>\n",
       "      <td>0.105771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6573</td>\n",
       "      <td>3</td>\n",
       "      <td>ModelName</td>\n",
       "      <td>0.004829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6573</td>\n",
       "      <td>under</td>\n",
       "      <td></td>\n",
       "      <td>0.007069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6573</td>\n",
       "      <td>$431</td>\n",
       "      <td>Price</td>\n",
       "      <td>0.004829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6574</td>\n",
       "      <td>apple</td>\n",
       "      <td>Brand</td>\n",
       "      <td>0.084158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6574</td>\n",
       "      <td>watch</td>\n",
       "      <td>Category</td>\n",
       "      <td>0.803335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6574</td>\n",
       "      <td>series</td>\n",
       "      <td>ModelName</td>\n",
       "      <td>0.105771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6574</td>\n",
       "      <td>3</td>\n",
       "      <td>ModelName</td>\n",
       "      <td>0.004829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6574</td>\n",
       "      <td>under</td>\n",
       "      <td></td>\n",
       "      <td>0.007069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6574</td>\n",
       "      <td>$64</td>\n",
       "      <td>Price</td>\n",
       "      <td>0.004829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6575</td>\n",
       "      <td>apple</td>\n",
       "      <td>Brand</td>\n",
       "      <td>0.084158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6575</td>\n",
       "      <td>watch</td>\n",
       "      <td>Category</td>\n",
       "      <td>0.803335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6575</td>\n",
       "      <td>series</td>\n",
       "      <td>ModelName</td>\n",
       "      <td>0.105771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6575</td>\n",
       "      <td>3</td>\n",
       "      <td>ModelName</td>\n",
       "      <td>0.004829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>6575</td>\n",
       "      <td>under</td>\n",
       "      <td></td>\n",
       "      <td>0.007069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>6575</td>\n",
       "      <td>$171</td>\n",
       "      <td>Price</td>\n",
       "      <td>0.004829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6575</td>\n",
       "      <td>honor</td>\n",
       "      <td>Brand</td>\n",
       "      <td>0.084158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>6575</td>\n",
       "      <td>6x</td>\n",
       "      <td>ModelName</td>\n",
       "      <td>0.083897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6577</td>\n",
       "      <td>honor</td>\n",
       "      <td>Brand</td>\n",
       "      <td>0.084158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>6577</td>\n",
       "      <td>6x</td>\n",
       "      <td>ModelName</td>\n",
       "      <td>0.083897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>6577</td>\n",
       "      <td>under</td>\n",
       "      <td></td>\n",
       "      <td>0.009083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>6577</td>\n",
       "      <td>$636</td>\n",
       "      <td>Price</td>\n",
       "      <td>0.004829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>6578</td>\n",
       "      <td>honor</td>\n",
       "      <td>Brand</td>\n",
       "      <td>0.084158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>6578</td>\n",
       "      <td>6x</td>\n",
       "      <td>ModelName</td>\n",
       "      <td>0.083897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>6590</td>\n",
       "      <td>$395</td>\n",
       "      <td>Price</td>\n",
       "      <td>0.006209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>6591</td>\n",
       "      <td>sequin</td>\n",
       "      <td>Category</td>\n",
       "      <td>0.084158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>6591</td>\n",
       "      <td>under</td>\n",
       "      <td></td>\n",
       "      <td>0.007033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>6591</td>\n",
       "      <td>$207</td>\n",
       "      <td>Price</td>\n",
       "      <td>0.006209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>6591</td>\n",
       "      <td>smoothie</td>\n",
       "      <td>RAM</td>\n",
       "      <td>0.084158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>6593</td>\n",
       "      <td>smoothie</td>\n",
       "      <td>RAM</td>\n",
       "      <td>0.084158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>6593</td>\n",
       "      <td>under</td>\n",
       "      <td></td>\n",
       "      <td>0.007033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>6593</td>\n",
       "      <td>$941</td>\n",
       "      <td>Price</td>\n",
       "      <td>0.006209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>6594</td>\n",
       "      <td>smoothie</td>\n",
       "      <td>RAM</td>\n",
       "      <td>0.084158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>6594</td>\n",
       "      <td>under</td>\n",
       "      <td></td>\n",
       "      <td>0.007033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>6594</td>\n",
       "      <td>$297</td>\n",
       "      <td>Price</td>\n",
       "      <td>0.006209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>6595</td>\n",
       "      <td>smoothie</td>\n",
       "      <td>RAM</td>\n",
       "      <td>0.084158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>6595</td>\n",
       "      <td>under</td>\n",
       "      <td></td>\n",
       "      <td>0.007033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>6595</td>\n",
       "      <td>$810</td>\n",
       "      <td>Price</td>\n",
       "      <td>0.006209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>6595</td>\n",
       "      <td>hw-m550</td>\n",
       "      <td>ModelName</td>\n",
       "      <td>0.023233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>6597</td>\n",
       "      <td>hw-m550</td>\n",
       "      <td>ModelName</td>\n",
       "      <td>0.023233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>6597</td>\n",
       "      <td>under</td>\n",
       "      <td></td>\n",
       "      <td>0.007033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>6597</td>\n",
       "      <td>$474</td>\n",
       "      <td>Price</td>\n",
       "      <td>0.006209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>6598</td>\n",
       "      <td>hw-m550</td>\n",
       "      <td>ModelName</td>\n",
       "      <td>0.023233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>6598</td>\n",
       "      <td>under</td>\n",
       "      <td></td>\n",
       "      <td>0.007033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>6598</td>\n",
       "      <td>$847</td>\n",
       "      <td>Price</td>\n",
       "      <td>0.006209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>6599</td>\n",
       "      <td>hw-m550</td>\n",
       "      <td>ModelName</td>\n",
       "      <td>0.023233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>6599</td>\n",
       "      <td>under</td>\n",
       "      <td></td>\n",
       "      <td>0.007033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>6599</td>\n",
       "      <td>$590</td>\n",
       "      <td>Price</td>\n",
       "      <td>0.006209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>6599</td>\n",
       "      <td>dryer</td>\n",
       "      <td>Category</td>\n",
       "      <td>0.664506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>6601</td>\n",
       "      <td>dryer</td>\n",
       "      <td>Category</td>\n",
       "      <td>0.664506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>6601</td>\n",
       "      <td>under</td>\n",
       "      <td></td>\n",
       "      <td>0.007033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>6601</td>\n",
       "      <td>$705</td>\n",
       "      <td>Price</td>\n",
       "      <td>0.006209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>6602</td>\n",
       "      <td>dryer</td>\n",
       "      <td>Category</td>\n",
       "      <td>0.664506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>6602</td>\n",
       "      <td>under</td>\n",
       "      <td></td>\n",
       "      <td>0.007033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    TupleID      word        Tag  Category\n",
       "0      6571     apple      Brand  0.084158\n",
       "1      6571     watch   Category  0.803335\n",
       "2      6571    series  ModelName  0.105771\n",
       "3      6571         3  ModelName  0.004829\n",
       "4      6573     apple      Brand  0.084158\n",
       "5      6573     watch   Category  0.803335\n",
       "6      6573    series  ModelName  0.105771\n",
       "7      6573         3  ModelName  0.004829\n",
       "8      6573     under             0.007069\n",
       "9      6573      $431      Price  0.004829\n",
       "10     6574     apple      Brand  0.084158\n",
       "11     6574     watch   Category  0.803335\n",
       "12     6574    series  ModelName  0.105771\n",
       "13     6574         3  ModelName  0.004829\n",
       "14     6574     under             0.007069\n",
       "15     6574       $64      Price  0.004829\n",
       "16     6575     apple      Brand  0.084158\n",
       "17     6575     watch   Category  0.803335\n",
       "18     6575    series  ModelName  0.105771\n",
       "19     6575         3  ModelName  0.004829\n",
       "20     6575     under             0.007069\n",
       "21     6575      $171      Price  0.004829\n",
       "22     6575     honor      Brand  0.084158\n",
       "23     6575        6x  ModelName  0.083897\n",
       "24     6577     honor      Brand  0.084158\n",
       "25     6577        6x  ModelName  0.083897\n",
       "26     6577     under             0.009083\n",
       "27     6577      $636      Price  0.004829\n",
       "28     6578     honor      Brand  0.084158\n",
       "29     6578        6x  ModelName  0.083897\n",
       "..      ...       ...        ...       ...\n",
       "70     6590      $395      Price  0.006209\n",
       "71     6591    sequin   Category  0.084158\n",
       "72     6591     under             0.007033\n",
       "73     6591      $207      Price  0.006209\n",
       "74     6591  smoothie        RAM  0.084158\n",
       "75     6593  smoothie        RAM  0.084158\n",
       "76     6593     under             0.007033\n",
       "77     6593      $941      Price  0.006209\n",
       "78     6594  smoothie        RAM  0.084158\n",
       "79     6594     under             0.007033\n",
       "80     6594      $297      Price  0.006209\n",
       "81     6595  smoothie        RAM  0.084158\n",
       "82     6595     under             0.007033\n",
       "83     6595      $810      Price  0.006209\n",
       "84     6595   hw-m550  ModelName  0.023233\n",
       "85     6597   hw-m550  ModelName  0.023233\n",
       "86     6597     under             0.007033\n",
       "87     6597      $474      Price  0.006209\n",
       "88     6598   hw-m550  ModelName  0.023233\n",
       "89     6598     under             0.007033\n",
       "90     6598      $847      Price  0.006209\n",
       "91     6599   hw-m550  ModelName  0.023233\n",
       "92     6599     under             0.007033\n",
       "93     6599      $590      Price  0.006209\n",
       "94     6599     dryer   Category  0.664506\n",
       "95     6601     dryer   Category  0.664506\n",
       "96     6601     under             0.007033\n",
       "97     6601      $705      Price  0.006209\n",
       "98     6602     dryer   Category  0.664506\n",
       "99     6602     under             0.007033\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev_result[:100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
